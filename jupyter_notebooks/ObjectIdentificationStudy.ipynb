{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Object Identification Study**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer business requirement 1:\n",
        "    * The client wants a study of the CIFAR-10 dataset, including understanding class distribution, sample images, and identifying any challenges such as imbalanced classes.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/cifar10_dataset_small/train\n",
        "* inputs/cifar10_dataset_small/validation\n",
        "* inputs/cifar10_dataset_small/test\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Mean and standard deviation of pixel values across the dataset\n",
        "* Analysis of differences between images from similar classes\n",
        "* Evaluation of pixel distributions\n",
        "* Plot showing the number of images per class for training, validation, and test sets\n",
        "* Code to generate and display an image montage for each class on a dashboard\n",
        "* Pickle files:\n",
        "    * class_labels.pkl: Contains the list of class labels\n",
        "    * image_counts.pkl: Contains the number of images per class for training, validation, and test sets\n",
        "    * label_mapping.pkl: Maps class labels to unique integer values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "sns.set_style(\"white\")\n",
        "from matplotlib.image import imread\n",
        "from PIL import Image\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change and Set directories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "print('Current folder: ' + current_dir)\n",
        "os.chdir(os.path.dirname(current_dir))\n",
        "current_dir = os.getcwd()\n",
        "print('New folder: ' + current_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset root directory and paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_root_dir = 'inputs/cifar10_dataset_small'\n",
        "train_path = dataset_root_dir + '/train'\n",
        "validation_path = dataset_root_dir + '/validation'\n",
        "test_path = dataset_root_dir + '/test'\n",
        "train_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set the output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v1'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(current_dir) and version in os.listdir(current_dir + '/outputs'):\n",
        "    print(f'Version {version} is already available.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)\n",
        "    print(f'New directory for version {version} has been created')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set the label names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = os.listdir(train_path)\n",
        "labels.sort()\n",
        "print(\"Class names:\", labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the avarage image size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "dim1, dim2 = [], []\n",
        "for label in labels:\n",
        "    for image_filename in os.listdir(train_path + '/' + label):\n",
        "        img = imread(train_path + '/' + label + '/' + image_filename)\n",
        "        d1, d2, colors = img.shape\n",
        "        dim1.append(d1)  # image height\n",
        "        dim2.append(d2)  # image width\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "fig, axes = plt.subplots()\n",
        "sns.scatterplot(x=dim2, y=dim1, alpha=0.2)\n",
        "axes.set_xlabel(\"Width (pixels)\")\n",
        "axes.set_ylabel(\"Height (pixels)\")\n",
        "dim1_mean = int(np.array(dim1).mean())\n",
        "dim2_mean = int(np.array(dim2).mean())\n",
        "axes.axvline(x=dim1_mean, color='r', linestyle='--')\n",
        "axes.axhline(y=dim2_mean, color='r', linestyle='--')\n",
        "plt.show()\n",
        "print(f\"Width average: {dim2_mean} \\nHeight average: {dim1_mean}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Images size for training the model is the average from all images in the train set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_shape = (dim1_mean, dim2_mean, 3)\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save the image shape embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=image_shape ,\n",
        "            filename=f\"{file_path}/image_shape.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Sample Images from Each Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the data is image-based, we will use a Python library like PIL (Python Imaging Library) to load example images and analyze its structure. Given that all images have the same size, we can assume uniformity in their dimensions and processing requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 5, figsize=(15, 6))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "    # Load the first image from each class\n",
        "    image_path = os.path.join(train_path, label, os.listdir(os.path.join(train_path, label))[0])\n",
        "    image = Image.open(image_path)\n",
        "    \n",
        "    # Get image size\n",
        "    width, height = image.size\n",
        "    \n",
        "    \n",
        "    axs[i].imshow(image)\n",
        "    \n",
        "    # Title with label and image size\n",
        "    axs[i].set_title(f'{label}\\n{width}x{height}')\n",
        "    \n",
        "    \n",
        "    axs[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Class distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We build upon the work done in the previous notebook where the CIFAR-10 dataset was reduced and divided into training, validation and test sets.\n",
        "As plotted below, there are exactly 350 images/class in the train set, 100 images/class in the test set and 50 images/class in validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_images_in_path(path):\n",
        "    class_counts = {}\n",
        "    for label in labels:\n",
        "        label_path = os.path.join(path, label)\n",
        "        class_counts[label] = len(os.listdir(label_path))\n",
        "    return class_counts\n",
        "\n",
        "# Count images in train, validation, and test sets\n",
        "train_counts = count_images_in_path(train_path)\n",
        "validation_counts = count_images_in_path(validation_path)\n",
        "test_counts = count_images_in_path(test_path)\n",
        "\n",
        "# Convert to DataFrame for plotting\n",
        "train_df = pd.DataFrame(list(train_counts.items()), columns=['Class', 'Train'])\n",
        "validation_df = pd.DataFrame(list(validation_counts.items()), columns=['Class', 'Validation'])\n",
        "test_df = pd.DataFrame(list(test_counts.items()), columns=['Class', 'Test'])\n",
        "\n",
        "# Merge dataframes for visualization\n",
        "df = pd.merge(train_df, validation_df, on='Class')\n",
        "df = pd.merge(df, test_df, on='Class')\n",
        "\n",
        "# Plot the number of images per class for train, validation, and test sets\n",
        "df.set_index('Class').plot(kind='bar', figsize=(12, 6))\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Number of Images per Class in Train, Validation, and Test Sets')\n",
        "plt.xticks(rotation=45)\n",
        "plt.savefig(f\"{file_path}/distribution_plot.png\", bbox_inches='tight', dpi=150)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Serialize Class Names and Counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Store the image counts, class labels and the converted class labels for future use in the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the class labels\n",
        "class_labels_path = os.path.join(file_path, 'class_labels.pkl')\n",
        "with open(class_labels_path, 'wb') as f:\n",
        "    pickle.dump(labels, f)\n",
        "print(f\"Class labels saved to {class_labels_path}\")\n",
        "\n",
        "# Save the image counts\n",
        "image_counts_path = os.path.join(file_path, 'image_counts.pkl')\n",
        "image_counts = {'train': train_counts, 'validation': validation_counts, 'test': test_counts}\n",
        "with open(image_counts_path, 'wb') as f:\n",
        "    pickle.dump(image_counts, f)\n",
        "print(f\"Image counts saved to {image_counts_path}\")\n",
        "\n",
        "# Mapping from class labels to integers\n",
        "label_mapping = {label: idx for idx, label in enumerate(labels)}\n",
        "\n",
        "\n",
        "label_mapping_path = os.path.join(file_path, 'label_mapping.pkl')\n",
        "with open(label_mapping_path, 'wb') as f:\n",
        "    pickle.dump(label_mapping, f)\n",
        "print(f\"Label mapping saved to {label_mapping_path}\")\n",
        "\n",
        "print(\"Label mapping:\", label_mapping)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mean and Standard deviation of pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize lists to store pixel values\n",
        "pixel_values = []\n",
        "\n",
        "\n",
        "for label in labels:\n",
        "    label_path = os.path.join(train_path, label)\n",
        "    \n",
        "    for image_file in os.listdir(label_path):\n",
        "        image_path = os.path.join(label_path, image_file)\n",
        "        image = Image.open(image_path)\n",
        "        \n",
        "        # Convert image to a NumPy array and normalize pixel values to [0, 1] range\n",
        "        image_array = np.array(image) / 255.0\n",
        "        \n",
        "        \n",
        "        pixel_values.append(image_array)\n",
        "\n",
        "\n",
        "pixel_values = np.stack(pixel_values)\n",
        "\n",
        "# Calculate the mean and standard deviation across all pixel values (for each RGB channel)\n",
        "mean = np.mean(pixel_values, axis=(0, 1, 2))\n",
        "std_dev = np.std(pixel_values, axis=(0, 1, 2))\n",
        "\n",
        "print(f'Mean of pixel values: {mean}')\n",
        "print(f'Standard deviation of pixel values: {std_dev}')\n",
        "\n",
        "# Plotting the Mean and Standard Deviation\n",
        "labels_rgb = ['Red', 'Green', 'Blue']\n",
        "\n",
        "# Create a figure and axes (mean and std deviation)\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Plot - mean\n",
        "axs[0].bar(labels_rgb, mean, color=['red', 'green', 'blue'])\n",
        "axs[0].set_title('Mean Pixel Values by Channel')\n",
        "axs[0].set_ylim(0, 1)  # Pixel values are normalized between 0 and 1\n",
        "axs[0].set_ylabel('Mean')\n",
        "\n",
        "# Plot - standard deviation\n",
        "axs[1].bar(labels_rgb, std_dev, color=['red', 'green', 'blue'])\n",
        "axs[1].set_title('Standard Deviation of Pixel Values by Channel')\n",
        "axs[1].set_ylim(0, 1)  # Also in the normalized pixel range\n",
        "axs[1].set_ylabel('Standard Deviation')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variability study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pixel-wise average of all images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_average_image(image_list):\n",
        "    average_image = np.mean(np.stack(image_list), axis=0)\n",
        "    return np.clip(average_image, 0, 1)  # Ensure values are in [0, 1] range\n",
        "\n",
        "# Initialize lists to store average images\n",
        "average_images = []\n",
        "\n",
        "for label in labels:\n",
        "    label_path = os.path.join(train_path, label)\n",
        "    images = [Image.open(os.path.join(label_path, image_file)) for image_file in os.listdir(label_path)]\n",
        "    image_arrays = [np.array(image) / 255.0 for image in images]\n",
        "    avg_image = compute_average_image(image_arrays)\n",
        "    average_images.append(avg_image)\n",
        "\n",
        "# Plot the average images\n",
        "fig, axs = plt.subplots(2, 5, figsize=(15, 6))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, (label, avg_image) in enumerate(zip(labels, average_images)):\n",
        "    axs[i].imshow(avg_image)\n",
        "    axs[i].set_title(label)\n",
        "    axs[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save or plot mean and variability of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_images_as_array(my_data_dir, new_size=(32, 32), n_images_per_label=20):\n",
        "    \"\"\"\n",
        "    Loads images into a numpy array, resizing and normalizing them.\n",
        "\n",
        "    Args:\n",
        "        my_data_dir (str): Directory containing subdirectories for each label.\n",
        "        new_size (tuple): Size to which each image will be resized.\n",
        "        n_images_per_label (int): Maximum number of images per label to load.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (X, y) where X is an array of images and y is an array of labels.\n",
        "    \"\"\"\n",
        "    labels = os.listdir(my_data_dir)\n",
        "    num_labels = len(labels)\n",
        "    \n",
        "    # Initialize arrays\n",
        "    X = np.zeros((num_labels * n_images_per_label, new_size[0], new_size[1], 3), dtype=np.float32)\n",
        "    y = np.zeros(num_labels * n_images_per_label, dtype=object)\n",
        "    \n",
        "    for label_index, label in enumerate(labels):\n",
        "        label_path = os.path.join(my_data_dir, label)\n",
        "        image_files = os.listdir(label_path)[:n_images_per_label]\n",
        "        \n",
        "        for img_index, image_filename in enumerate(image_files):\n",
        "            image_path = os.path.join(label_path, image_filename)\n",
        "            img = Image.open(image_path).resize(new_size)  # Resizing to new_size\n",
        "            \n",
        "            # Convert image to array and normalize\n",
        "            img_array = np.array(img) / 255.0\n",
        "            \n",
        "            # Fill the preallocated array\n",
        "            X[label_index * n_images_per_label + img_index] = img_array\n",
        "            y[label_index * n_images_per_label + img_index] = label\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Usage\n",
        "image_shape = (32, 32)  # Keeping original size\n",
        "X, y = load_images_as_array(my_data_dir=train_path, new_size=image_shape, n_images_per_label=8)\n",
        "print(X.shape, y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_mean_variability_per_labels(X, y, figsize=(12, 5), save_image=False):\n",
        "    \"\"\"\n",
        "    Plots the mean and variability of images for each label.\n",
        "\n",
        "    Args:\n",
        "        X (numpy.ndarray): Array of images (shape: [num_images, height, width, channels]).\n",
        "        y (numpy.ndarray): Labels for images.\n",
        "        figsize (tuple): Size of the figure to be plotted.\n",
        "        save_image (bool): If True, saves the plot as an image file.\n",
        "        file_path (str): Directory to save the image files.\n",
        "    \"\"\"\n",
        "    unique_labels = np.unique(y)\n",
        "    \n",
        "    if save_image and not os.path.exists(file_path):\n",
        "        os.makedirs(file_path)\n",
        "\n",
        "    for label_to_display in unique_labels:\n",
        "        sns.set_style(\"white\")\n",
        "        \n",
        "        # Create a mask for images with the current label\n",
        "        boolean_mask = (y == label_to_display)\n",
        "        arr = X[boolean_mask]\n",
        "        \n",
        "        # Calculate average and standard deviation images\n",
        "        avg_img = np.mean(arr, axis=0)\n",
        "        std_img = np.std(arr, axis=0)\n",
        "        \n",
        "        print(f\"==== Label {label_to_display} ====\")\n",
        "        print(f\"Image Shape: {avg_img.shape}\")\n",
        "        \n",
        "        # Normalize images for display\n",
        "        avg_img = (avg_img - np.min(avg_img)) / (np.max(avg_img) - np.min(avg_img))\n",
        "        std_img = (std_img - np.min(std_img)) / (np.max(std_img) - np.min(std_img))\n",
        "        \n",
        "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=figsize)\n",
        "        axes[0].set_title(f\"Average image for label {label_to_display}\")\n",
        "        axes[0].imshow(avg_img)\n",
        "        axes[0].axis('off')\n",
        "        axes[1].set_title(f\"Variability image for label {label_to_display}\")\n",
        "        axes[1].imshow(std_img)\n",
        "        axes[1].axis('off')\n",
        "        \n",
        "        if save_image:\n",
        "            plt.savefig(f\"{file_path}/avg_var_{label_to_display}.png\", bbox_inches='tight', dpi=150)\n",
        "        else:\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_mean_variability_per_labels(X=X, y=y, figsize=(12, 5), save_image=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Differentiate between average images from similar classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def diff_bet_avg_image_labels_data(X, y, label_pairs, figsize=(15, 5), save_image=False):\n",
        "    \"\"\"\n",
        "    Calculates and plots the average images and differences between specified pairs of labels.\n",
        "\n",
        "    Args:\n",
        "        X (numpy.ndarray): Array of images (shape: [num_images, height, width, channels]).\n",
        "        y (numpy.ndarray): Array of labels.\n",
        "        label_pairs (list of tuples): List of tuples where each tuple contains two labels to compare.\n",
        "        figsize (tuple): Size of the plot.\n",
        "        save_image (bool): Whether to save the plot as an image.\n",
        "        file_path (str): Directory path to save the image if save_image is True.\n",
        "    \"\"\"\n",
        "    sns.set_style(\"white\")\n",
        "    \n",
        "    # Ensure output directory exists\n",
        "    if save_image and not os.path.exists(file_path):\n",
        "        os.makedirs(file_path)\n",
        "\n",
        "    unique_labels = np.unique(y)\n",
        "    \n",
        "    for label1, label2 in label_pairs:\n",
        "        if (label1 not in unique_labels) or (label2 not in unique_labels):\n",
        "            print(f\"Skipping comparison: Either label '{label1}' or label '{label2}' is not in the dataset.\")\n",
        "            continue\n",
        "\n",
        "        # Mean image for label1\n",
        "        images_label1 = X[y == label1]\n",
        "        label1_avg = np.mean(images_label1, axis=0)\n",
        "\n",
        "        # Mean image for label2\n",
        "        images_label2 = X[y == label2]\n",
        "        label2_avg = np.mean(images_label2, axis=0)\n",
        "\n",
        "        # Difference between average images\n",
        "        difference_mean = label1_avg - label2_avg\n",
        "        \n",
        "        # Normalize images for display\n",
        "        label1_avg = (label1_avg - np.min(label1_avg)) / (np.max(label1_avg) - np.min(label1_avg))\n",
        "        label2_avg = (label2_avg - np.min(label2_avg)) / (np.max(label2_avg) - np.min(label2_avg))\n",
        "        difference_mean = (difference_mean - np.min(difference_mean)) / (np.max(difference_mean) - np.min(difference_mean))\n",
        "        \n",
        "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=figsize)\n",
        "        axes[0].imshow(label1_avg)\n",
        "        axes[0].set_title(f'Average {label1}')\n",
        "        axes[0].axis('off')\n",
        "        \n",
        "        axes[1].imshow(label2_avg)\n",
        "        axes[1].set_title(f'Average {label2}')\n",
        "        axes[1].axis('off')\n",
        "        \n",
        "        axes[2].imshow(difference_mean)\n",
        "        axes[2].set_title(f'Difference: {label1} - {label2}')\n",
        "        axes[2].axis('off')\n",
        "        \n",
        "        if save_image:\n",
        "            plt.savefig(f\"{file_path}/avg_diff_{label1}_{label2}.png\", bbox_inches='tight', dpi=150)\n",
        "        else:\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "label_pairs = [\n",
        "    ('deer', 'horse'),\n",
        "    ('truck', 'automobile'),\n",
        "    ('airplane', 'bird')\n",
        "]\n",
        "\n",
        "diff_bet_avg_image_labels_data(X=X, y=y, label_pairs=label_pairs, figsize=(15, 5), save_image=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image Montage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_image_montage(image_list, title, ncols=3):\n",
        "    n_images = len(image_list)\n",
        "    n_rows = (n_images + ncols - 1) // ncols\n",
        "    fig, axs = plt.subplots(n_rows, ncols, figsize=(ncols * 3, n_rows * 3))\n",
        "    axs = axs.flatten()\n",
        "    \n",
        "    for i, img in enumerate(image_list):\n",
        "        axs[i].imshow(img)\n",
        "        axs[i].axis('off')\n",
        "    \n",
        "    # Hide any unused subplots\n",
        "    for i in range(n_images, len(axs)):\n",
        "        axs[i].axis('off')\n",
        "    \n",
        " \n",
        "    plt.suptitle(title, fontsize=16, y=0.95)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "for label in labels:\n",
        "    label_path = os.path.join(train_path, label)\n",
        "    image_files = os.listdir(label_path)\n",
        "    images = [Image.open(os.path.join(label_path, image_file)) for image_file in image_files[:3]]  # Display first 3 images in class\n",
        "    plot_image_montage(images, title=label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions and Next steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Images from study has been saved to output folder.\n",
        "\n",
        "\n",
        "### Observations:\n",
        "The bad resolution of the small images makes it hard to see any differances.\n",
        "Images are too similar to get good results from image study comparison.\n",
        "\n",
        "### Next Steps:\n",
        "Proceed to next notebook for Modelling and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
